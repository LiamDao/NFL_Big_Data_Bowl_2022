---
title: "Expected Return Yards XGBoost Model"
output: html_notebook
---

# File Setup
## Import Packages & Read in Data
```{r import packages, warning = FALSE, message=FALSE}
library(tidyverse)
library(caret)
library(leaps)
library(glmnet)
library(ggplot2)
library(earth)
library(mgcv)
library(ROCR)
library(Cairo)
library(pROC)
library(ROCR)
library(randomForest)
library(xgboost)
library(Ckmeans.1d.dp)
library(pdp)
library(Matrix)
library(gganimate)
library(cowplot)
library(ggridges)
library(repr)
library(gifski)
library(plotly)

#turning off warnings
options(warn=-1)

#set directory
setwd("C:/Users/liamd/Documents/GitHub/NFL_Big_Data_Bowl_2022")
punts_df <- read.csv("df_plays_punts.csv")

punts_return_df <- punts_df %>% 
  filter(specialTeamsResult == "Return") %>% 
  filter(!is.na(kickReturnYardage))

# Subset to train and test
set.seed(4321)
training <- punts_return_df %>% sample_frac(0.7)
testing <- anti_join(punts_return_df, training, by = 'X')
```


## Data Exploration
```{r data exploration}
lapply(punts_df, class)

summary(punts_return_df$kickReturnYardage)
```


# XG Boost Modeling
## Base Model
```{r base model}
set.seed(4321)

# Set all columns in df that are factor to ordinal (needed for XGBoost)
for (col in colnames(df)) {
  if (class(df[,col]) == "factor") {
    df[,col] <- ordered(df[,col])
  }
    }
  
# Create matrix for x and vector for y
train_x <- model.matrix(kickReturnYardage ~ quarter + down + yardsToGo + yardlineNumber + preSnapHomeScore + preSnapVisitorScore
                        + kickLength, data = training)[,-1]
train_y <- training$kickReturnYardage

# Model
xgb.yard <- xgboost(data = train_x, label = train_y, subsample = .5, nrounds = 100)
```


## Parameter Tuning
```{r parameter tuning}
set.seed(4321)

# Get nrounds first
xgb.yard.cv <- xgb.cv(data = train_x, label = train_y, subsample = .5, nrounds = 100, nfold = 10)
# Other parameters: eta, max_depth, gamma, colsample_bytree, min_child_weight

nrounds.results <- as.data.frame(xgb.yard.cv$evaluation_log)
nrounds.results[which.min(nrounds.results$test_rmse_mean),]
# Lowest rmse value (10.95142) has nrounds = 4

# Create tuning grid
tune_grid <- expand.grid(
  nrounds = 4,
  eta = seq(0, 1, by = 0.1),
  max_depth = c(1:10),
  gamma = c(0),
  colsample_bytree = 1,
  min_child_weight = 1,
  subsample = seq(0, 1, by = 0.1)
)

# Tune parameters
xgb.yard.caret <- train(x = train_x, y = train_y,
      method = "xgbTree",
      tuneGrid = tune_grid,
      trControl = trainControl(method = 'cv', # Using 10-fold cross-validation
                               number = 10))
plot(xgb.yard.caret)

tune.results <- as.data.frame(xgb.yard.caret$results)
tune.results[which.min(tune.results$RMSE),]
```
> After first tune:
* nrounds = 4
* subsample = .3
* max_depth = 1
* eta = .6
* gamma = 0
* colsample_bytree = 1
* min_child_weight = 1
* Test RMSE = 10.52559

## Tuning playground
```{r tuning playground}
set.seed(4321)

# Create tuning grid
tune_grid <- expand.grid(
  nrounds = 4,
  eta = seq(.25, .40, by = 0.01),
  max_depth = c(1:3),
  gamma = c(1:10),
  colsample_bytree = 1,
  min_child_weight = 1,
  subsample = seq(.25, .35, by = 0.01)
)

# Tune parameters
xgb.yard.caret <- train(x = train_x, y = train_y,
      method = "xgbTree",
      tuneGrid = tune_grid,
      trControl = trainControl(method = 'cv', # Using 10-fold cross-validation
                               number = 10))
plot(xgb.yard.caret)

tune.results <- as.data.frame(xgb.yard.caret$results)
tune.results[which.min(tune.results$RMSE),]

set.seed(4321)

# Get nrounds first
xgb.yard.cv <- xgb.cv(data = train_x, label = train_y, subsample = .33, max_depth = 1, eta = .39, gamma = 7,
                      colsample_bytree = 1, min_child_weight = 1, nrounds = 100, nfold = 10)
# Other parameters: eta, max_depth, gamma, colsample_bytree, min_child_weight

nrounds.results <- as.data.frame(xgb.yard.cv$evaluation_log)
nrounds.results[which.min(nrounds.results$test_rmse_mean),]
```
> Current Interation:
* nrounds = 5
* subsample = .33
* max_depth = 1
* eta = .39
* gamma = 7
* colsample_bytree = 1
* min_child_weight = 1
* Test RMSE = 10.51416
